{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot import PlotLossesKeras\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "fer_directory = 'data/FER2013'\n",
    "ck_directory = 'data/CK+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise generator with rescale factor 1./255\n",
    "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "# Preprocess training set\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Preprocess test set\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import types\n",
    "\n",
    "\n",
    "class KerasBatchClassifier(KerasClassifier):\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "\n",
    "        # taken from keras.wrappers.scikit_learn.KerasClassifier.fit ###################################################\n",
    "        if self.build_fn is None:\n",
    "            self.model = self.__call__(**self.filter_sk_params(self.__call__))\n",
    "        elif not isinstance(self.build_fn, types.FunctionType) and not isinstance(self.build_fn, types.MethodType):\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn.__call__))\n",
    "        else:\n",
    "            self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "\n",
    "        ################################################################################################################\n",
    "        datagen = ImageDataGenerator(\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "        if 'X_val' in kwargs and 'y_val' in kwargs:\n",
    "            X_val = kwargs['X_val']\n",
    "            y_val = kwargs['y_val']\n",
    "\n",
    "            val_gen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                horizontal_flip=True\n",
    "            )\n",
    "            val_flow = val_gen.flow(X_val, y_val, batch_size=32)\n",
    "            val_steps = len(X_val) / 32\n",
    "\n",
    "            early_stopping = EarlyStopping( patience=5, verbose=5, mode=\"auto\")\n",
    "            model_checkpoint = ModelCheckpoint(\"results/best_weights.{epoch:02d}-{loss:.5f}.hdf5\", verbose=5, save_best_only=True, mode=\"auto\")\n",
    "        else:\n",
    "            val_flow = None\n",
    "            val_steps = None\n",
    "            early_stopping = EarlyStopping(monitor=\"acc\", patience=3, verbose=5, mode=\"auto\")\n",
    "            model_checkpoint = ModelCheckpoint(\"results/best_weights.{epoch:02d}-{loss:.5f}.hdf5\", monitor=\"acc\", verbose=5, save_best_only=True, mode=\"auto\")\n",
    "\n",
    "        callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "        epochs = self.sk_params['epochs'] if 'epochs' in self.sk_params else 100\n",
    "\n",
    "        self.__history = self.model.fit_generator(\n",
    "            datagen.flow(X, y, batch_size=32),  \n",
    "            steps_per_epoch=len(X) / 32,\n",
    "            validation_data=val_flow, \n",
    "            validation_steps=val_steps, \n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        return self.__history\n",
    "\n",
    "    def score(self, X, y, **kwargs):\n",
    "        kwargs = self.filter_sk_params(Sequential.evaluate, kwargs)\n",
    "\n",
    "        loss_name = self.model.loss\n",
    "        if hasattr(loss_name, '__name__'):\n",
    "            loss_name = loss_name.__name__\n",
    "        if loss_name == 'categorical_crossentropy' and len(y.shape) != 2:\n",
    "            y = to_categorical(y)\n",
    "        outputs = self.model.evaluate(X, y, **kwargs)\n",
    "        if type(outputs) is not list:\n",
    "            outputs = [outputs]\n",
    "        for name, output in zip(self.model.metrics_names, outputs):\n",
    "            if name == 'acc':\n",
    "                return output\n",
    "        raise Exception('The model is not configured to compute accuracy. '\n",
    "                        'You should pass `metrics=[\"accuracy\"]` to '\n",
    "                        'the `model.compile()` method.')\n",
    "\n",
    "    @property\n",
    "    def history(self):\n",
    "        return self.__history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023C0965DCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.227 total time=   8.7s\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023C0A368D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.190 total time=   8.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.143 total time=   8.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.227 total time=   8.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.190 total time=   8.9s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.286 total time=   9.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.227 total time=   8.8s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.190 total time=   8.9s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.143 total time=   9.0s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.227 total time=  10.1s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.190 total time=   9.6s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.095 total time=   8.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.227 total time=   8.4s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.095 total time=   9.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.048 total time=   9.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.227 total time=   9.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.095 total time=   9.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.286 total time=   9.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.227 total time=  10.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.190 total time=  11.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.143 total time=   9.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.227 total time=   9.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.190 total time=  11.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.238 total time=  12.1s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.182 total time=   9.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.190 total time=   9.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.238 total time=   8.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.227 total time=   8.4s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.190 total time=  10.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.143 total time=   8.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.273 total time=   9.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.238 total time=   9.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.095 total time=  10.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.182 total time=   9.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.143 total time=   9.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.095 total time=   8.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=   8.9s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.190 total time=   9.9s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.143 total time=   9.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.091 total time=   9.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.190 total time=   9.8s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.238 total time=   9.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.273 total time=  12.9s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.190 total time=  12.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.095 total time=  10.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.227 total time=   9.4s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.190 total time=   8.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.143 total time=  10.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.318 total time=  11.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=  10.0s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.143 total time=   9.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.318 total time=  10.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.190 total time=  10.6s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.095 total time=  10.0s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.000 total time=   9.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.238 total time=   8.8s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.286 total time=   8.5s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.227 total time=   9.6s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.190 total time=   9.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.143 total time=   9.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.273 total time=   8.6s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.095 total time=  11.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.190 total time=  10.3s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.318 total time=   9.8s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.238 total time=   9.8s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.095 total time=   9.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.273 total time=  11.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.190 total time=  10.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.143 total time=   9.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.227 total time=   9.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.190 total time=  10.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.143 total time=  10.8s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.000 total time=  10.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.190 total time=  10.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.095 total time=  10.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.318 total time=  10.8s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.190 total time=  10.5s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.000 total time=  11.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.364 total time=   9.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.190 total time=   8.8s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.143 total time=  10.5s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.227 total time=   9.8s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.190 total time=   9.0s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.095 total time=   9.3s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.091 total time=   8.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.190 total time=   9.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.286 total time=   8.9s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.091 total time=   8.4s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.095 total time=   8.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.143 total time=   8.3s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.227 total time=   8.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.095 total time=   8.8s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.286 total time=   8.3s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.091 total time=   7.8s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.190 total time=   9.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.143 total time=   8.9s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.227 total time=   8.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.190 total time=   8.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.143 total time=   8.5s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.091 total time=   9.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.190 total time=   9.0s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.143 total time=   8.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.227 total time=   8.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.190 total time=   8.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.238 total time=   9.1s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.227 total time=   8.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.190 total time=   8.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.095 total time=   8.2s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.227 total time=   7.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.190 total time=   9.5s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.286 total time=   8.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.318 total time=   8.1s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.143 total time=   8.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.190 total time=   7.9s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.136 total time=   8.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.143 total time=   8.5s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.286 total time=   8.2s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=   8.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.190 total time=   8.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.143 total time=   9.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.273 total time=   8.7s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.190 total time=   8.6s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.238 total time=   8.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.318 total time=   9.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.190 total time=   8.9s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.095 total time=   8.6s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.091 total time=   8.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.190 total time=   8.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.143 total time=   9.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.000 total time=   8.9s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.190 total time=   8.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=   8.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.182 total time=   8.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.238 total time=   9.7s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.095 total time=   8.9s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.091 total time=   8.2s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.238 total time=   8.1s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.238 total time=   9.4s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.227 total time=   8.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.190 total time=   8.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.143 total time=   8.2s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.227 total time=   8.0s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.190 total time=   9.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.143 total time=   8.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.091 total time=   8.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.190 total time=   8.2s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.095 total time=   8.1s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.318 total time=   9.5s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.190 total time=   9.0s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.190 total time=   8.7s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.273 total time=   8.3s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.048 total time=   8.5s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.143 total time=   9.1s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.318 total time=   8.6s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.190 total time=   8.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.095 total time=   8.2s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.273 total time=   9.9s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.190 total time=   9.3s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.143 total time=   8.9s\n",
      "[CV 1/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.227 total time=   8.4s\n",
      "[CV 2/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=   8.4s\n",
      "[CV 3/3] END activation=relu, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=  13.1s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.227 total time=  12.0s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.190 total time=  11.4s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.143 total time=  12.1s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.091 total time=  12.7s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.095 total time=  14.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.238 total time=  13.2s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.091 total time=  11.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.190 total time=  11.3s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.238 total time=  10.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.091 total time=  14.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.190 total time=  13.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.143 total time=  12.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.136 total time=  11.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.190 total time=  11.3s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.238 total time=  14.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.091 total time=  13.5s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.143 total time=  13.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.286 total time=  11.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.227 total time=  10.2s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.095 total time=  15.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.095 total time=  13.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.091 total time=  12.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.238 total time=  12.3s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.190 total time=  15.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.091 total time=  13.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.143 total time=  11.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.238 total time=  10.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.091 total time=   9.1s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.190 total time=  10.6s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.095 total time=  10.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.091 total time=   9.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.238 total time=   9.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.190 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.091 total time=  10.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.238 total time=  10.2s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.143 total time=   9.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=   9.3s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.095 total time=   9.5s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.143 total time=   9.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.091 total time=   9.7s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.095 total time=   9.6s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.286 total time=   9.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.091 total time=  10.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.190 total time=  11.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.238 total time=  10.1s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.227 total time=   9.5s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.190 total time=   9.5s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.095 total time=  10.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.091 total time=   9.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.190 total time=  10.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.238 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.091 total time=   9.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.190 total time=  10.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.190 total time=  10.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.000 total time=   9.4s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.190 total time=   9.6s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.286 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.318 total time=  10.4s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.286 total time=   9.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.143 total time=   9.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.091 total time=   9.3s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.095 total time=   9.5s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.238 total time=  10.5s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.227 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.238 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.286 total time=   9.5s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.045 total time=   9.7s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.095 total time=  10.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.143 total time=  10.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.227 total time=   9.5s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.095 total time=   9.6s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.238 total time=  10.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.000 total time=  10.0s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.190 total time=  10.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.238 total time=   9.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.045 total time=   9.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.238 total time=  10.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.095 total time=  10.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.091 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=   9.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.238 total time=   9.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.227 total time=  10.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.095 total time=  10.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.286 total time=   9.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.091 total time=   9.5s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.095 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.190 total time=  11.4s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.091 total time=  10.2s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.190 total time=  10.2s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.095 total time=   9.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.091 total time=   9.3s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.190 total time=  11.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.286 total time=  10.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.091 total time=  10.0s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.286 total time=   9.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.238 total time=   9.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.091 total time=  10.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.095 total time=  10.5s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.286 total time=  10.1s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.091 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.190 total time=   9.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.095 total time=  10.1s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.364 total time=   9.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.190 total time=  10.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.190 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.045 total time=  10.7s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.190 total time=  10.3s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.238 total time=  10.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.091 total time=   9.4s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.190 total time=   9.4s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.143 total time=  10.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.091 total time=  10.1s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.238 total time=   9.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.286 total time=   9.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.091 total time=   9.4s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.095 total time=  11.3s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.238 total time=  10.5s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.190 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.143 total time=   9.5s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.091 total time=  10.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.143 total time=  10.5s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.238 total time=  10.2s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.091 total time=   9.7s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.190 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.286 total time=  11.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.091 total time=  10.2s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.190 total time=  10.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.286 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.091 total time=  10.1s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.238 total time=  10.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=  10.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.091 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.048 total time=   9.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.238 total time=  11.4s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.227 total time=  10.3s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.095 total time=   9.9s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.143 total time=   9.6s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.000 total time=   9.4s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.190 total time=  11.0s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.286 total time=  10.3s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.227 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.095 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.238 total time=   9.5s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.091 total time=  10.9s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.190 total time=  10.6s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.143 total time=  10.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.091 total time=   9.8s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.190 total time=   9.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.286 total time=  11.0s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.000 total time=  10.2s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.190 total time=  10.1s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.286 total time=   9.9s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.227 total time=   9.6s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.095 total time=  11.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.143 total time=  11.7s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.318 total time=  10.0s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.095 total time=   9.8s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.095 total time=   9.8s\n",
      "[CV 1/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.318 total time=  11.2s\n",
      "[CV 2/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.190 total time=  10.7s\n",
      "[CV 3/3] END activation=tanh, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.238 total time=  10.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.091 total time=   9.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.238 total time=  10.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.095 total time=  10.5s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.091 total time=  10.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.095 total time=   9.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.143 total time=   9.8s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.091 total time=  11.6s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.190 total time=  14.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.095 total time=  13.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.045 total time=  12.0s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.190 total time=  11.6s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.286 total time=  15.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.000 total time=  13.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.238 total time=  13.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.143 total time=  12.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.000 total time=  11.3s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.190 total time=  15.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.095 total time=  14.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.227 total time=  13.1s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.190 total time=  12.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.000 total time=  11.7s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.000 total time=  15.1s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.095 total time=  14.3s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.095 total time=  13.3s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.000 total time=  12.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.095 total time=  11.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.238 total time=  15.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.227 total time=  13.6s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.190 total time=  12.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.286 total time=  12.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.045 total time=  11.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.190 total time=  13.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.143 total time=  12.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.045 total time=  12.1s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.190 total time=  11.3s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.143 total time=  15.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=  13.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.190 total time=  13.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.143 total time=  12.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.000 total time=  11.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.095 total time=  14.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.143 total time=  14.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.000 total time=  13.3s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.190 total time=  12.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.143 total time=  11.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.227 total time=  14.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.095 total time=  14.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.286 total time=  13.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.091 total time=  12.0s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=  11.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=  15.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.000 total time=  13.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.095 total time=  13.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.095 total time=  12.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.091 total time=  11.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.238 total time=  15.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.143 total time=  14.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.227 total time=  12.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.095 total time=  12.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.238 total time=  10.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.091 total time=  14.3s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.095 total time=  13.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.286 total time=  12.6s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.045 total time=  11.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.095 total time=  11.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.238 total time=  13.8s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.091 total time=  12.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.095 total time=  12.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.095 total time=  11.3s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.000 total time=  14.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.095 total time=  13.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.095 total time=  12.6s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.227 total time=  11.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.190 total time=  11.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.143 total time=  15.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.045 total time=  13.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.095 total time=  12.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.286 total time=  12.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.045 total time=  11.4s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=  15.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.1, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=  13.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.318 total time=  12.6s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.095 total time=  12.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=0;, score=0.238 total time=  11.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.318 total time=  14.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.095 total time=  13.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=1;, score=0.238 total time=  12.8s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.000 total time=  11.8s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.190 total time=  11.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=64, weight_constraint=2;, score=0.143 total time=  14.8s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.000 total time=  13.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.238 total time=  12.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=0;, score=0.286 total time=  12.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.227 total time=  11.6s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.095 total time=  13.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=1;, score=0.286 total time=  12.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.045 total time=  11.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.238 total time=  11.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=128, weight_constraint=2;, score=0.095 total time=  15.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.091 total time=  13.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.095 total time=  13.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=0;, score=0.095 total time=  12.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.000 total time=  11.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.095 total time=  15.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=1;, score=0.095 total time=  14.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.318 total time=  12.8s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.095 total time=  12.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.001, neurons=256, weight_constraint=2;, score=0.095 total time=  12.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.000 total time=  14.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.095 total time=  13.9s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=0;, score=0.095 total time=  13.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.045 total time=  12.0s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.190 total time=  11.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=1;, score=0.095 total time=  15.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.091 total time=  13.6s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.095 total time=  13.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=64, weight_constraint=2;, score=0.095 total time=  12.3s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.091 total time=  10.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.095 total time=  14.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=0;, score=0.095 total time=  13.5s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.045 total time=  12.4s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.095 total time=  12.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=1;, score=0.286 total time=  11.7s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.091 total time=  13.3s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.095 total time=  12.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=128, weight_constraint=2;, score=0.095 total time=  12.2s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.000 total time=  11.1s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.095 total time=  11.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=0;, score=0.286 total time=  15.3s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.045 total time=  13.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.238 total time=  13.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=1;, score=0.095 total time=  12.5s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.091 total time=  11.5s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.190 total time=  15.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.01, neurons=256, weight_constraint=2;, score=0.095 total time=  14.1s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.091 total time=  12.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.190 total time=  12.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=0;, score=0.238 total time=  15.0s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.091 total time=  13.7s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.095 total time=  13.0s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=1;, score=0.095 total time=  12.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.318 total time=  11.3s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.190 total time=  15.1s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=64, weight_constraint=2;, score=0.286 total time=  13.9s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.318 total time=  12.8s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.238 total time=  12.3s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=0;, score=0.143 total time=  11.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.000 total time=  14.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.095 total time=  14.2s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=1;, score=0.333 total time=  13.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.091 total time=  12.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.095 total time=  11.7s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=128, weight_constraint=2;, score=0.095 total time=  15.4s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.227 total time=  14.1s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.095 total time=  13.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=0;, score=0.143 total time=  12.5s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.091 total time=  11.9s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.095 total time=  15.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=1;, score=0.286 total time=  14.3s\n",
      "[CV 1/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.000 total time=  13.2s\n",
      "[CV 2/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.238 total time=  12.5s\n",
      "[CV 3/3] END activation=sigmoid, dropout_rate=0.2, learning_rate=0.1, neurons=256, weight_constraint=2;, score=0.095 total time=  12.1s\n",
      "Best: 0.264791 using {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.234488 (0.039214) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.170996 (0.055635) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.123377 (0.075994) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.202742 (0.079673) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.218615 (0.020382) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.203463 (0.024742) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.202020 (0.076819) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.139971 (0.035405) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.173160 (0.061323) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.186147 (0.072524) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.185426 (0.095865) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.201299 (0.091338) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.174603 (0.124984) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.186147 (0.072524) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.217172 (0.092211) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.202020 (0.053644) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.095238 (0.077762) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.169553 (0.130737) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.232323 (0.094866) with: {'activation': 'relu', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.170996 (0.055635) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.189033 (0.079535) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.109668 (0.023535) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.202742 (0.079673) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.141414 (0.040661) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.218615 (0.020382) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.170996 (0.055635) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.234488 (0.039214) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.217172 (0.074023) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.188312 (0.068925) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.233766 (0.033718) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.201299 (0.091338) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.095238 (0.077762) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.171717 (0.058757) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.189033 (0.069384) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.186869 (0.034557) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.125541 (0.045950) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.233045 (0.060201) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.154401 (0.092262) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.201299 (0.091338) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.202020 (0.053644) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.139250 (0.062242) with: {'activation': 'relu', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.141414 (0.068387) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.173160 (0.061323) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.188312 (0.041560) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.173160 (0.082365) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.139250 (0.062242) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.173160 (0.061323) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.157287 (0.060949) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.125541 (0.045950) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.173160 (0.061323) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.157287 (0.060949) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.109668 (0.023535) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.157287 (0.090829) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.173160 (0.061323) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.170996 (0.055635) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.173160 (0.061323) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.157287 (0.046936) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.158730 (0.118783) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.248918 (0.076158) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.141414 (0.068387) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.250361 (0.025386) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.094517 (0.039768) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.186869 (0.064943) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.142857 (0.102869) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.126263 (0.081648) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.141414 (0.068387) with: {'activation': 'tanh', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.202742 (0.079673) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.125541 (0.045950) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.125541 (0.045950) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.189033 (0.079535) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.204906 (0.082919) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.157287 (0.090829) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.125541 (0.045950) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.248196 (0.081628) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.158009 (0.081928) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.204906 (0.082919) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.141414 (0.068387) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.157287 (0.060949) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.189033 (0.079535) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.189033 (0.079535) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.141414 (0.068387) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.125541 (0.081526) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.155123 (0.054596) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.158730 (0.118783) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.186869 (0.064943) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.189033 (0.079535) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.158730 (0.118783) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.155123 (0.054596) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.169553 (0.105097) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.248918 (0.052694) with: {'activation': 'tanh', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.141414 (0.068387) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.109668 (0.023535) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.125541 (0.045950) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.173882 (0.098785) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.126984 (0.097848) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.095238 (0.077762) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.139250 (0.099604) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.063492 (0.044896) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.111111 (0.097848) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.234488 (0.039214) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.126263 (0.060356) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.126263 (0.060356) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.141414 (0.040661) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.079365 (0.059391) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.111111 (0.080937) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.202742 (0.079673) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.063492 (0.044896) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.157287 (0.060949) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.186869 (0.064943) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.157287 (0.090829) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.126263 (0.081648) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.063492 (0.044896) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.186869 (0.034557) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.142136 (0.103540) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.078644 (0.023468) with: {'activation': 'sigmoid', 'dropout_rate': 0.1, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.217172 (0.092211) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.217172 (0.092211) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.111111 (0.080937) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.174603 (0.124984) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.202742 (0.079673) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.126263 (0.081648) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.063492 (0.044896) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.169553 (0.105097) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.001, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.063492 (0.044896) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.110390 (0.060166) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.142136 (0.103540) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.126984 (0.118783) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.126263 (0.081648) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.125541 (0.045950) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.01, 'neurons': 256, 'weight_constraint': 2}\n",
      "0.173160 (0.061323) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 0}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 1}\n",
      "0.264791 (0.054194) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 64, 'weight_constraint': 2}\n",
      "0.233045 (0.071665) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 0}\n",
      "0.142857 (0.140187) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 1}\n",
      "0.093795 (0.002041) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 128, 'weight_constraint': 2}\n",
      "0.155123 (0.054596) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 0}\n",
      "0.157287 (0.090829) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 1}\n",
      "0.111111 (0.097848) with: {'activation': 'sigmoid', 'dropout_rate': 0.2, 'learning_rate': 0.1, 'neurons': 256, 'weight_constraint': 2}\n"
     ]
    }
   ],
   "source": [
    "# Grid search for optimal hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define model\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.0, weight_constraint=0, neurons=64, activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), input_shape=(48,48,1), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation=activation))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons, activation=activation, kernel_constraint=max_norm(weight_constraint)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "experiment_model = KerasClassifier(model=create_model, epochs=10, batch_size=64, verbose=0, activation='relu', dropout_rate=0.1, learning_rate=0.001, neurons=64, weight_constraint=0)\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.1, 0.2]\n",
    "weight_constraint = [0, 1, 2]\n",
    "neurons = [64, 128, 256]\n",
    "activation = ['relu', 'tanh', 'sigmoid']\n",
    "\n",
    "# Split training set into X and y\n",
    "(X_train, Y_train) = train_generator.next()\n",
    "\n",
    "# Define grid search\n",
    "param_grid = dict(learning_rate=learning_rate, dropout_rate=dropout_rate, weight_constraint=weight_constraint, neurons=neurons, activation=activation)\n",
    "grid = GridSearchCV(estimator=experiment_model, param_grid=param_grid, n_jobs=1, cv=3, verbose=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_494\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2961 (Conv2D)        (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_3455 (B  (None, 48, 48, 64)       256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1482 (MaxPool  (None, 24, 24, 64)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_1976 (Dropout)      (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2962 (Conv2D)        (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_3456 (B  (None, 24, 24, 128)      512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1483 (MaxPool  (None, 12, 12, 128)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_1977 (Dropout)      (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2963 (Conv2D)        (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_3457 (B  (None, 12, 12, 512)      2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1484 (MaxPool  (None, 6, 6, 512)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " dropout_1978 (Dropout)      (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten_494 (Flatten)       (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_988 (Dense)           (None, 256)               4718848   \n",
      "                                                                 \n",
      " batch_normalization_3458 (B  (None, 256)              1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1979 (Dropout)      (None, 256)               0         \n",
      "                                                                 \n",
      " dense_989 (Dense)           (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,520,391\n",
      "Trainable params: 5,518,471\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st convolution layer\n",
    "model.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 2nd convolution layer\n",
    "model.add(Conv2D(128, (5,5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 3rd convolution layer\n",
    "model.add(Conv2D(512, (3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten and feed into dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots image\n",
    "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "# Image('model.png',width=400, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.317, max:    0.317, cur:    0.317)\n",
      "\tvalidation       \t (min:    0.315, max:    0.315, cur:    0.315)\n",
      "Loss\n",
      "\ttraining         \t (min:    1.815, max:    1.815, cur:    1.815)\n",
      "\tvalidation       \t (min:    1.879, max:    1.879, cur:    1.879)\n",
      "lr\n",
      "\tlr               \t (min:    0.000, max:    0.000, cur:    0.000)\n",
      "448/448 [==============================] - 472s 1s/step - loss: 1.8147 - accuracy: 0.3169 - val_loss: 1.8788 - val_accuracy: 0.3153 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "312/448 [===================>..........] - ETA: 2:12 - loss: 1.6141 - accuracy: 0.3830"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3bba42a9e441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 40\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps = test_generator.n//test_generator.batch_size\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "# Save model weights\n",
    "checkpoint = ModelCheckpoint('model_weights.h5', monitor='val_accuracy', save_weights_only=True, mode='max', verbose=1)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint, reduce_lr, PlotLossesKeras()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('Accuracy.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
