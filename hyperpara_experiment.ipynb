{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "fer_directory = 'data/FER2013'\n",
    "ck_directory = 'data/CK+'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise generator with rescale factor 1./255\n",
    "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "\n",
    "# Preprocess training set\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Preprocess test set\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=64,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal hyperparameters\n",
    "\n",
    "# Define model\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.1, neurons=64):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(128, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(512, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(neurons))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "experiment_model = KerasClassifier(model=create_model, epochs=10, verbose=2, dropout_rate=0.1, learning_rate=0.001, neurons=64)\n",
    "\n",
    "# Define hyperparameters\n",
    "dropout_rate = [0.1, 0.2, 0.3, 0.4]\n",
    "neurons = [64, 128, 256]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "\n",
    "# Split training set into X and y\n",
    "(X_train, Y_train) = train_generator.next()\n",
    "print(X_train.shape, Y_train.shape)\n",
    "# Define grid search\n",
    "param_grid = dict(dropout_rate=dropout_rate, neurons=neurons,learning_rate=learning_rate)\n",
    "grid = GridSearchCV(estimator=experiment_model, param_grid=param_grid, n_jobs=1, cv=3, verbose=3)\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
