{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0aeb7ccdfec1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfer_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/FER2013'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mck_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/CK+'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num GPUs Available: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\config.py\u001b[0m in \u001b[0;36mlist_physical_devices\u001b[1;34m(device_type)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdiscovered\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPhysicalDevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m   \"\"\"\n\u001b[1;32m--> 423\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mlist_physical_devices\u001b[1;34m(self, device_type)\u001b[0m\n\u001b[0;32m   1491\u001b[0m       \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPhysicalDevice\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m     \"\"\"\n\u001b[1;32m-> 1493\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m_initialize_physical_devices\u001b[1;34m(self, reinitialize)\u001b[0m\n\u001b[0;32m   1447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m       \u001b[0mdevs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_ListPhysicalDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m       self._physical_devices = [\n\u001b[0m\u001b[0;32m   1450\u001b[0m           \u001b[0mPhysicalDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "fer_directory = 'data/FER2013'\n",
    "ck_directory = 'data/CK+'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3591 images belonging to 7 classes.\n",
      "Found 3587 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise generator with rescale factor 1./255\n",
    "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=10,  zoom_range=0.1, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, rotation_range=10, zoom_range=0.1, horizontal_flip=True, validation_split=0.5)\n",
    "\n",
    "# Preprocess training set\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "# Preprocess test set\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "validation_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_conv_filter_1 = hp.Int('conv_filter_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_2 = hp.Int('conv_filter_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_3 = hp.Int('conv_filter_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_dropout = hp.Float('conv_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_2, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_3, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(hp_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 45m 18s]\n",
      "val_accuracy: 0.5331823825836182\n",
      "\n",
      "Best val_accuracy So Far: 0.5742902159690857\n",
      "Total elapsed time: 10h 09m 32s\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x000001F9BB68A550>\n"
     ]
    }
   ],
   "source": [
    "def create_model(hp):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_conv_filter_1 = hp.Int('conv_filter_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_2 = hp.Int('conv_filter_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_3 = hp.Int('conv_filter_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_dropout = hp.Float('conv_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_2, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_3, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(hp_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./first_model_experiment',\n",
    "    project_name='facial_expression_recognition'\n",
    ")\n",
    "\n",
    "# Stop training when validation loss stops improving\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print results\n",
    "print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_filter_1': 64, 'conv_filter_2': 320, 'conv_filter_3': 512, 'conv_dropout': 0.0, 'units': 512, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0012'}\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_model(hp):\n",
    "    # Reference model\n",
    "    ref_model = Sequential()\n",
    "\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    hp_conv_filters_1 = hp.Int('conv_filters_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_2 = hp.Int('conv_filters_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_3 = hp.Int('conv_filters_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_4 = hp.Int('conv_filters_4', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_5 = hp.Int('conv_filters_5', min_value=64, max_value=512, step=64)\n",
    "    ref_model.add(Conv2D(hp_conv_filters_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    ref_model.add(Conv2D(hp_conv_filters_2, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_3, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_4, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_5, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    hp_dense_filter = hp.Int('dense_filter', min_value=32, max_value=512, step=32)\n",
    "    ref_model.add(Flatten())\n",
    "    ref_model.add(Dense(hp_dense_filter, activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "\n",
    "    hp_dense_dropout = hp.Float('dense_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    ref_model.add(Dropout(hp_dense_dropout))\n",
    "    ref_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    ref_model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return ref_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 40m 48s]\n",
      "val_accuracy: 0.5725483298301697\n",
      "\n",
      "Best val_accuracy So Far: 0.6093015074729919\n",
      "Total elapsed time: 05h 22m 46s\n",
      "{'dropout': 0.30000000000000004, 'conv_filters_1': 256, 'conv_filters_2': 384, 'conv_filters_3': 320, 'conv_filters_4': 192, 'conv_filters_5': 192, 'dense_filter': 352, 'dense_dropout': 0.1, 'learning_rate': 0.001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0019'}\n"
     ]
    }
   ],
   "source": [
    "ref_tuner = kt.Hyperband(\n",
    "    create_ref_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./ref_model_experiment',\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "ref_tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "print (ref_tuner.get_best_hyperparameters(num_trials=1)[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    model = Sequential()\n",
    "    # 1st convolution layer\n",
    "    hp_conv_filter_1 = hp.Int('filter layer 1', min_value=32, max_value=512, step=32)\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"1st layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"1st layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 2nd Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 2\", min_value=32, max_value=512, step=32), (5,5), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"2nd layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"2nd layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 3rd Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 3\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"3rd layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"3rd layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 4th Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 4\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"4th layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"4th layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 5th Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 5\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"5th layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"5th layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune number of dense layers from 1 to 3\n",
    "    for i in range(1, hp.Int(\"dense layer\", 1, 3)):\n",
    "        model.add(Dense(hp.Int(\"dense layer \" + str(i), min_value=128, max_value=1024, step=64), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 11m 15s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 11m 43s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "448               |480               |filter layer 1\n",
      "1                 |2                 |1st layer additional\n",
      "320               |32                |filter layer 2\n",
      "0                 |2                 |2nd layer additional\n",
      "384               |416               |filter layer 3\n",
      "0                 |1                 |3rd layer additional\n",
      "480               |32                |filter layer 4\n",
      "1                 |0                 |4th layer additional\n",
      "480               |192               |filter layer 5\n",
      "2                 |0                 |5th layer additional\n",
      "2                 |2                 |dense layer\n",
      "256               |32                |1st layer with 0 extra layer\n",
      "64                |32                |1st layer with 1 extra layer\n",
      "256               |32                |2nd layer with 0 extra layer\n",
      "160               |32                |2nd layer with 1 extra layer\n",
      "320               |32                |3rd layer with 0 extra layer\n",
      "896               |128               |dense layer 1\n",
      "32                |None              |5th layer with 0 extra layer\n",
      "288               |None              |5th layer with 1 extra layer\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "3                 |3                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n",
      "      super().run_forever()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "      lambda f: self._run_callback(functools.partial(callback, future))\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "      ret = callback()\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "      self.ctx_run(self.run)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "      yielded = self.gen.send(value)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n",
      "      yield gen.maybe_future(dispatch(*args))\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n",
      "      yield gen.maybe_future(handler(stream, idents, msg))\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n",
      "      self.do_execute(\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "      yielded = ctx_run(next, result)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n",
      "      res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n",
      "      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "      if (await self.run_code(code, result,  async_=asy)):\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"<ipython-input-5-8edd008a3797>\", line 13, in <module>\n",
      "      model_tuner.search(train_generator, epochs=50, validation_data=validation_generator, callbacks=[stop_early])\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 233, in search\n",
      "      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n",
      "      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n",
      "      return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "      return model.fit(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n",
      "      return self.activation(outputs)\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n",
      "      return backend.relu(\n",
      "    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n",
      "      x = tf.nn.relu(x)\n",
      "Node: 'sequential/conv2d/Relu'\n",
      "No algorithm worked!  Error messages:\n",
      "  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n",
      "  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n",
      "  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
      "  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n",
      "  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n",
      "  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n",
      "  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n",
      "  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n",
      "  Profiling failure on CUDNN engine 6#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n",
      "  Profiling failure on CUDNN engine 6: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n",
      "  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n",
      "  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n",
      "  Profiling failure on CUDNN engine 7#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n",
      "  Profiling failure on CUDNN engine 7: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n",
      "\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_8670]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.NotFoundError: Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-8edd008a3797>\", line 13, in <module>\n      model_tuner.search(train_generator, epochs=50, validation_data=validation_generator, callbacks=[stop_early])\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 233, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n      return model.fit(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n  Profiling failure on CUDNN engine 6#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n  Profiling failure on CUDNN engine 6: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n  Profiling failure on CUDNN engine 7#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n  Profiling failure on CUDNN engine 7: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_8670]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8edd008a3797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mstop_early\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m                 raise RuntimeError(\n\u001b[0m\u001b[0;32m    535\u001b[0m                     \u001b[1;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m                     \u001b[1;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.NotFoundError: Graph execution error:\n\nDetected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\windows_events.py\", line 316, in run_forever\n      super().run_forever()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n      ret = callback()\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n      self.ctx_run(self.run)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n      yielded = self.gen.send(value)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 536, in execute_request\n      self.do_execute(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2894, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3165, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3437, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-8edd008a3797>\", line 13, in <module>\n      model_tuner.search(train_generator, epochs=50, validation_data=validation_generator, callbacks=[stop_early])\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 233, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\tuners\\hyperband.py\", line 427, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n      return model.fit(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n      return backend.relu(\n    File \"c:\\Users\\subse\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n      x = tf.nn.relu(x)\nNode: 'sequential/conv2d/Relu'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16793216 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 27394048 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1954561792 bytes.\n  Profiling failure on CUDNN engine 6#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n  Profiling failure on CUDNN engine 6: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17026560 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 518963200 bytes.\n  Profiling failure on CUDNN engine 7#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n  Profiling failure on CUDNN engine 7: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 1208581120 bytes.\n\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_8670]\n"
     ]
    }
   ],
   "source": [
    "model_tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='./model_selection_experiment_2',\n",
    "    overwrite=False, # Reload from checkpoint\n",
    "    project_name=\"fer\"\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_tuner.search(train_generator, epochs=50, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filter layer 1': 96, '1st layer additional': 1, 'filter layer 2': 224, '2nd layer additional': 0, 'filter layer 3': 32, '3rd layer additional': 1, 'filter layer 4': 416, '4th layer additional': 0, 'filter layer 5': 480, '5th layer additional': 0, 'dense layer': 1, '1st layer with 0 extra layer': 480, '1st layer with 1 extra layer': 320, '5th layer with 0 extra layer': 160, 'dense layer 1': 640, 'dense layer 2': 320, '2nd layer with 0 extra layer': 480, '2nd layer with 1 extra layer': 448, '3rd layer with 0 extra layer': 480, '3rd layer with 1 extra layer': 320, '4th layer with 0 extra layer': 320, '5th layer with 1 extra layer': 224, '4th layer with 1 extra layer': 128, 'tuner/epochs': 15, 'tuner/initial_epoch': 5, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0020'}\n"
     ]
    }
   ],
   "source": [
    "print(model_tuner.get_best_hyperparameters(num_trials=1)[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test hyperband with number of layers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    model = Sequential()\n",
    "    # 1st convolution layer\n",
    "    hp_conv_filter_1 = hp.Int('filter layer 1', min_value=32, max_value=512, step=32)\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"1st layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"1st layer with \" + str(i + 1) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Try adding 1 to 5 more conv layers\n",
    "    for i in range(1, hp.Int(\"Additional hidden layers\", 1, 5)):\n",
    "        model.add(Conv2D(hp.Int(\"filter layer \" + str(i+1), min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "        # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "        for j in range(0, hp.Int(str(i+1) + \"th layer additional\", 0, 2)):\n",
    "            model.add(Conv2D(hp.Int(str(i+1) + \"th layer with \" + str(j + 1) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "     # Tune number of dense layers from 1 to 3\n",
    "    for i in range(1, hp.Int(\"dense layer\", 1, 3)):\n",
    "        model.add(Dense(hp.Int(\"dense layer \" + str(i+1), min_value=128, max_value=1024, step=64), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8edd008a3797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model_tuner = kt.Hyperband(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcreate_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kt' is not defined"
     ]
    }
   ],
   "source": [
    "model_tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='./model_selection_experiment_2',\n",
    "    overwrite=False, # Reload from checkpoint\n",
    "    project_name=\"fer\"\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_tuner.search(train_generator, epochs=50, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
