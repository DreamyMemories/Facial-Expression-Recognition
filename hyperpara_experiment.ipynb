{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "fer_directory = 'data/FER2013'\n",
    "ck_directory = 'data/CK+'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3591 images belonging to 7 classes.\n",
      "Found 3587 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise generator with rescale factor 1./255\n",
    "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=10,  zoom_range=0.1, horizontal_flip=True)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, rotation_range=10, zoom_range=0.1, horizontal_flip=True, validation_split=0.5)\n",
    "\n",
    "# Preprocess training set\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "# Preprocess test set\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "validation_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_conv_filter_1 = hp.Int('conv_filter_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_2 = hp.Int('conv_filter_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_3 = hp.Int('conv_filter_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_dropout = hp.Float('conv_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_2, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_3, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(hp_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 45m 18s]\n",
      "val_accuracy: 0.5331823825836182\n",
      "\n",
      "Best val_accuracy So Far: 0.5742902159690857\n",
      "Total elapsed time: 10h 09m 32s\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x000001F9BB68A550>\n"
     ]
    }
   ],
   "source": [
    "def create_model(hp):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_conv_filter_1 = hp.Int('conv_filter_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_2 = hp.Int('conv_filter_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_3 = hp.Int('conv_filter_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_dropout = hp.Float('conv_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_2, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_3, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_conv_dropout))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(Dense(hp_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./first_model_experiment',\n",
    "    project_name='facial_expression_recognition'\n",
    ")\n",
    "\n",
    "# Stop training when validation loss stops improving\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print results\n",
    "print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_filter_1': 64, 'conv_filter_2': 320, 'conv_filter_3': 512, 'conv_dropout': 0.0, 'units': 512, 'dropout': 0.30000000000000004, 'learning_rate': 0.0001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '0012'}\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_model(hp):\n",
    "    # Reference model\n",
    "    ref_model = Sequential()\n",
    "\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    hp_conv_filters_1 = hp.Int('conv_filters_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_2 = hp.Int('conv_filters_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_3 = hp.Int('conv_filters_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_4 = hp.Int('conv_filters_4', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_5 = hp.Int('conv_filters_5', min_value=64, max_value=512, step=64)\n",
    "    ref_model.add(Conv2D(hp_conv_filters_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    ref_model.add(Conv2D(hp_conv_filters_2, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_3, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_4, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_5, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    hp_dense_filter = hp.Int('dense_filter', min_value=32, max_value=512, step=32)\n",
    "    ref_model.add(Flatten())\n",
    "    ref_model.add(Dense(hp_dense_filter, activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "\n",
    "    hp_dense_dropout = hp.Float('dense_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    ref_model.add(Dropout(hp_dense_dropout))\n",
    "    ref_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    ref_model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return ref_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 40m 48s]\n",
      "val_accuracy: 0.5725483298301697\n",
      "\n",
      "Best val_accuracy So Far: 0.6093015074729919\n",
      "Total elapsed time: 05h 22m 46s\n",
      "{'dropout': 0.30000000000000004, 'conv_filters_1': 256, 'conv_filters_2': 384, 'conv_filters_3': 320, 'conv_filters_4': 192, 'conv_filters_5': 192, 'dense_filter': 352, 'dense_dropout': 0.1, 'learning_rate': 0.001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0019'}\n"
     ]
    }
   ],
   "source": [
    "ref_tuner = kt.Hyperband(\n",
    "    create_ref_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./ref_model_experiment',\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "ref_tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "print (ref_tuner.get_best_hyperparameters(num_trials=1)[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Selection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    model = Sequential()\n",
    "    # 1st convolution layer\n",
    "    hp_conv_filter_1 = hp.Int('filter layer 1', min_value=32, max_value=512, step=32)\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"1st layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"1st layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 2nd Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 2\", min_value=32, max_value=512, step=32), (5,5), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"2nd layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"2nd layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 3rd Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 3\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"3rd layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"3rd layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 4th Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 4\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"4th layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"4th layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # 5th Convolution Layer\n",
    "    model.add(Conv2D(hp.Int(\"filter layer 5\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    # Loop to see whether we need to add 0 to 2 more conv layers\n",
    "    for i in range(0, hp.Int(\"5th layer additional\", 0, 2)):\n",
    "        model.add(Conv2D(hp.Int(\"5th layer with \" + str(i) + \" extra layer\", min_value=32, max_value=512, step=32), (3,3), padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune number of dense layers from 1 to 3\n",
    "    for i in range(1, hp.Int(\"dense layer\", 1, 3)):\n",
    "        model.add(Dense(hp.Int(\"dense layer \" + str(i), min_value=128, max_value=1024, step=64), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 Complete [00h 12m 24s]\n",
      "val_accuracy: 0.4803456962108612\n",
      "\n",
      "Best val_accuracy So Far: 0.530526876449585\n",
      "Total elapsed time: 06h 00m 29s\n"
     ]
    }
   ],
   "source": [
    "model_tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,\n",
    "    factor=3,\n",
    "    directory='./model_selection_experiment',\n",
    "    overwrite=False, # Reload from checkpoint\n",
    "    project_name=\"fer\"\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model_tuner.search(train_generator, epochs=15, validation_data=validation_generator, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filter layer 1': 96, '1st layer additional': 1, 'filter layer 2': 224, '2nd layer additional': 0, 'filter layer 3': 32, '3rd layer additional': 1, 'filter layer 4': 416, '4th layer additional': 0, 'filter layer 5': 480, '5th layer additional': 0, 'dense layer': 1, '1st layer with 0 extra layer': 480, '1st layer with 1 extra layer': 320, '5th layer with 0 extra layer': 160, 'dense layer 1': 640, 'dense layer 2': 320, '2nd layer with 0 extra layer': 480, '2nd layer with 1 extra layer': 448, '3rd layer with 0 extra layer': 480, '3rd layer with 1 extra layer': 320, '4th layer with 0 extra layer': 320, '5th layer with 1 extra layer': 224, '4th layer with 1 extra layer': 128, 'tuner/epochs': 15, 'tuner/initial_epoch': 5, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0020'}\n"
     ]
    }
   ],
   "source": [
    "print(model_tuner.get_best_hyperparameters(num_trials=1)[0].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
