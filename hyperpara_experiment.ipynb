{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "fer_directory = 'data/FER2013'\n",
    "ck_directory = 'data/CK+'\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialise generator with rescale factor 1./255\n",
    "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=10,  zoom_range=0.1, horizontal_flip=True, validation_split=0.2)\n",
    "test_gen = ImageDataGenerator(rescale=1./255, rotation_range=10, zoom_range=0.1, horizontal_flip=True)\n",
    "\n",
    "# Preprocess training set\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = train_gen.flow_from_directory(\n",
    "    fer_directory + '/train',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Preprocess test set\n",
    "test_generator = test_gen.flow_from_directory(\n",
    "    fer_directory + '/test',\n",
    "    target_size=(48,48),\n",
    "    batch_size=128,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 03m 09s]\n",
      "val_accuracy: 0.5495960116386414\n",
      "\n",
      "Best val_accuracy So Far: 0.6064363121986389\n",
      "Total elapsed time: 01h 01m 35s\n",
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x0000018C438A3EE0>\n"
     ]
    }
   ],
   "source": [
    "def create_model(hp):\n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    hp_conv_filter_1 = hp.Int('conv_filter_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_2 = hp.Int('conv_filter_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filter_3 = hp.Int('conv_filter_3', min_value=64, max_value=512, step=64)\n",
    "    # 1st convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_1, (3,3), padding='same', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # 2nd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_2, (5,5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # 3rd convolution layer\n",
    "    model.add(Conv2D(hp_conv_filter_3, (3,3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Flatten and feed into dense layer\n",
    "    model.add(Flatten())\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(hp_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(hp_dropout))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./test',\n",
    "    project_name='facial_expression_recognition'\n",
    ")\n",
    "\n",
    "# Stop training when validation loss stops improving\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Print results\n",
    "print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.1, 'units': 416, 'learning_rate': 0.0001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0023'}\n"
     ]
    }
   ],
   "source": [
    "print(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ref_model(hp):\n",
    "    # Reference model\n",
    "    ref_model = Sequential()\n",
    "\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    hp_conv_filters_1 = hp.Int('conv_filters_1', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_2 = hp.Int('conv_filters_2', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_3 = hp.Int('conv_filters_3', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_4 = hp.Int('conv_filters_4', min_value=64, max_value=512, step=64)\n",
    "    hp_conv_filters_5 = hp.Int('conv_filters_5', min_value=64, max_value=512, step=64)\n",
    "    ref_model.add(Conv2D(hp_conv_filters_1, (3,3), padding='same', input_shape=(48,48,1), activation='relu'))\n",
    "    ref_model.add(Conv2D(hp_conv_filters_2, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_3, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_4, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    ref_model.add(Conv2D(hp_conv_filters_5, (3,3), padding='same', activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "    ref_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    ref_model.add(Dropout(hp_dropout))\n",
    "\n",
    "    hp_dense_filter = hp.Int('dense_filter', min_value=32, max_value=512, step=32)\n",
    "    ref_model.add(Flatten())\n",
    "    ref_model.add(Dense(hp_dense_filter, activation='relu'))\n",
    "    ref_model.add(BatchNormalization())\n",
    "\n",
    "    hp_dense_dropout = hp.Float('dense_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    ref_model.add(Dropout(hp_dense_dropout))\n",
    "    ref_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    ref_model.compile(optimizer=Adam(learning_rate=hp_learning_rate, decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return ref_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 40m 48s]\n",
      "val_accuracy: 0.5725483298301697\n",
      "\n",
      "Best val_accuracy So Far: 0.6093015074729919\n",
      "Total elapsed time: 05h 22m 46s\n",
      "{'dropout': 0.30000000000000004, 'conv_filters_1': 256, 'conv_filters_2': 384, 'conv_filters_3': 320, 'conv_filters_4': 192, 'conv_filters_5': 192, 'dense_filter': 352, 'dense_dropout': 0.1, 'learning_rate': 0.001, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0019'}\n"
     ]
    }
   ],
   "source": [
    "ref_tuner = kt.Hyperband(\n",
    "    create_ref_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='./ref_model_experiment',\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "ref_tuner.search(train_generator, epochs=20, validation_data=validation_generator, callbacks=[stop_early])\n",
    "\n",
    "print (ref_tuner.get_best_hyperparameters(num_trials=1)[0].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
